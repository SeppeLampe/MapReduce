[
    {
        "author": "[{'name': 'Ahmed Osman'}, {'name': 'Wojciech Samek'}]",
        "day": 1,
        "id": "1802.00209v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.00209v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.00209v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "We propose an architecture for VQA which utilizes recurrent layers to\ngenerate visual and textual attention. The memory characteristic of the\nproposed recurrent attention units offers a rich joint embedding of visual and\ntextual features and enables the model to reason relations between several\nparts of the image and question. Our single model outperforms the first place\nwinner on the VQA 1.0 dataset, performs within margin to the current\nstate-of-the-art ensemble model. We also experiment with replacing attention\nmechanisms in other state-of-the-art models with our implementation and show\nincreased accuracy. In both cases, our recurrent attention mechanism improves\nperformance in tasks requiring sequential or relational reasoning on the VQA\ndataset.",
        "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Dual Recurrent Attention Units for Visual Question Answering",
        "year": 2018
    },
    {
        "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}]",
        "day": 12,
        "id": "1603.03827v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.03827v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.03827v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 3,
        "summary": "Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for short-text classification. However, many short texts\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\nand most existing ANN-based systems do not leverage the preceding short texts\nwhen classifying a subsequent one. In this work, we present a model based on\nrecurrent neural networks and convolutional neural networks that incorporates\nthe preceding short texts. Our model achieves state-of-the-art results on three\ndifferent datasets for dialog act prediction.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Sequential Short-Text Classification with Recurrent and Convolutional\n  Neural Networks",
        "year": 2016
    },
    {
        "author": "[{'name': 'Iulian Vlad Serban'}, {'name': 'Tim Klinger'}, {'name': 'Gerald Tesauro'}, {'name': 'Kartik Talamadupula'}, {'name': 'Bowen Zhou'}, {'name': 'Yoshua Bengio'}, {'name': 'Aaron Courville'}]",
        "day": 2,
        "id": "1606.00776v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.00776v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.00776v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation",
        "year": 2016
    },
    {
        "author": "[{'name': 'Sebastian Ruder'}, {'name': 'Joachim Bingel'}, {'name': 'Isabelle Augenstein'}, {'name': 'Anders S\u00f8gaard'}]",
        "day": 23,
        "id": "1705.08142v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08142v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08142v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "Multi-task learning is motivated by the observation that humans bring to bear\nwhat they know about related problems when solving new ones. Similarly, deep\nneural networks can profit from related tasks by sharing parameters with other\nnetworks. However, humans do not consciously decide to transfer knowledge\nbetween tasks. In Natural Language Processing (NLP), it is hard to predict if\nsharing will lead to improvements, particularly if tasks are only loosely\nrelated. To overcome this, we introduce Sluice Networks, a general framework\nfor multi-task learning where trainable parameters control the amount of\nsharing. Our framework generalizes previous proposals in enabling sharing of\nall combinations of subspaces, layers, and skip connections. We perform\nexperiments on three task pairs, and across seven different domains, using data\nfrom OntoNotes 5.0, and achieve up to 15% average error reductions over common\napproaches to multi-task learning. We show that a) label entropy is predictive\nof gains in sluice networks, confirming findings for hard parameter sharing and\nb) while sluice networks easily fit noise, they are robust across domains in\npractice.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Learning what to share between loosely related tasks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Chinnadhurai Sankar'}, {'name': 'Mathieu Germain'}, {'name': 'Saizheng Zhang'}, {'name': 'Zhouhan Lin'}, {'name': 'Sandeep Subramanian'}, {'name': 'Taesup Kim'}, {'name': 'Michael Pieper'}, {'name': 'Sarath Chandar'}, {'name': 'Nan Rosemary Ke'}, {'name': 'Sai Rajeshwar'}, {'name': 'Alexandre de Brebisson'}, {'name': 'Jose M. R. Sotelo'}, {'name': 'Dendi Suhubdy'}, {'name': 'Vincent Michalski'}, {'name': 'Alexandre Nguyen'}, {'name': 'Joelle Pineau'}, {'name': 'Yoshua Bengio'}]",
        "day": 7,
        "id": "1709.02349v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.02349v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.02349v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Deep Reinforcement Learning Chatbot",
        "year": 2017
    },
    {
        "author": "[{'name': 'Kelvin Guu'}, {'name': 'Tatsunori B. Hashimoto'}, {'name': 'Yonatan Oren'}, {'name': 'Percy Liang'}]",
        "day": 26,
        "id": "1709.08878v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.08878v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.08878v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Generating Sentences by Editing Prototypes",
        "year": 2017
    },
    {
        "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Chinnadhurai Sankar'}, {'name': 'Mathieu Germain'}, {'name': 'Saizheng Zhang'}, {'name': 'Zhouhan Lin'}, {'name': 'Sandeep Subramanian'}, {'name': 'Taesup Kim'}, {'name': 'Michael Pieper'}, {'name': 'Sarath Chandar'}, {'name': 'Nan Rosemary Ke'}, {'name': 'Sai Rajeswar'}, {'name': 'Alexandre de Brebisson'}, {'name': 'Jose M. R. Sotelo'}, {'name': 'Dendi Suhubdy'}, {'name': 'Vincent Michalski'}, {'name': 'Alexandre Nguyen'}, {'name': 'Joelle Pineau'}, {'name': 'Yoshua Bengio'}]",
        "day": 20,
        "id": "1801.06700v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.06700v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.06700v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 1,
        "summary": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Deep Reinforcement Learning Chatbot (Short Version)",
        "year": 2018
    },
    {
        "author": "[{'name': 'Darko Brodic'}, {'name': 'Alessia Amelio'}, {'name': 'Zoran N. Milivojevic'}, {'name': 'Milena Jevtic'}]",
        "day": 21,
        "id": "1609.06492v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.06492v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.06492v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '97R40, 62H35, 68U15, 68T50,', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Document Image Coding and Clustering for Script Discrimination",
        "year": 2016
    },
    {
        "author": "[{'name': 'Mateusz Malinowski'}, {'name': 'Mario Fritz'}]",
        "day": 4,
        "id": "1610.01076v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.01076v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.01076v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 10,
        "summary": "Together with the development of more accurate methods in Computer Vision and\nNatural Language Understanding, holistic architectures that answer on questions\nabout the content of real-world images have emerged. In this tutorial, we build\na neural-based approach to answer questions about images. We base our tutorial\non two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the\nmodels that we present here can achieve a competitive performance on both\ndatasets, in fact, they are among the best methods that use a combination of\nLSTM with a global, full frame CNN representation of an image. We hope that\nafter reading this tutorial, the reader will be able to use Deep Learning\nframeworks, such as Keras and introduced Kraino, to build various architectures\nthat will lead to a further performance improvement on this challenging task.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Tutorial on Answering Questions about Images with Deep Learning",
        "year": 2016
    },
    {
        "author": "[{'name': 'Fred Richardson'}, {'name': 'Douglas Reynolds'}, {'name': 'Najim Dehak'}]",
        "day": 3,
        "id": "1504.00923v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.00923v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.00923v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Learned feature representations and sub-phoneme posteriors from Deep Neural\nNetworks (DNNs) have been used separately to produce significant performance\ngains for speaker and language recognition tasks. In this work we show how\nthese gains are possible using a single DNN for both speaker and language\nrecognition. The unified DNN approach is shown to yield substantial performance\nimprovements on the the 2013 Domain Adaptation Challenge speaker recognition\ntask (55% reduction in EER for the out-of-domain condition) and on the NIST\n2011 Language Recognition Evaluation (48% reduction in EER for the 30s test\ncondition).",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Unified Deep Neural Network for Speaker and Language Recognition",
        "year": 2015
    },
    {
        "author": "[{'name': 'Hieu Pham'}, {'name': 'Melody Y. Guan'}, {'name': 'Barret Zoph'}, {'name': 'Quoc V. Le'}, {'name': 'Jeff Dean'}]",
        "day": 9,
        "id": "1802.03268v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.03268v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.03268v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Efficient Neural Architecture Search via Parameter Sharing",
        "year": 2018
    },
    {
        "author": "[{'name': 'Brenden M. Lake'}, {'name': 'Tomer D. Ullman'}, {'name': 'Joshua B. Tenenbaum'}, {'name': 'Samuel J. Gershman'}]",
        "day": 1,
        "id": "1604.00289v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.00289v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.00289v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels.",
        "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Building Machines That Learn and Think Like People",
        "year": 2016
    },
    {
        "author": "[{'name': 'Hao Wang'}, {'name': 'Dit-Yan Yeung'}]",
        "day": 6,
        "id": "1604.01662v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.01662v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.01662v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "While perception tasks such as visual object recognition and text\nunderstanding play an important role in human intelligence, the subsequent\ntasks that involve inference, reasoning and planning require an even higher\nlevel of intelligence. The past few years have seen major advances in many\nperception tasks using deep learning models. For higher-level inference,\nhowever, probabilistic graphical models with their Bayesian nature are still\nmore powerful and flexible. To achieve integrated intelligence that involves\nboth perception and inference, it is naturally desirable to tightly integrate\ndeep learning and Bayesian models within a principled probabilistic framework,\nwhich we call Bayesian deep learning. In this unified framework, the perception\nof text or images using deep learning can boost the performance of higher-level\ninference and in return, the feedback from the inference process is able to\nenhance the perception of text or images. This survey provides a general\nintroduction to Bayesian deep learning and reviews its recent applications on\nrecommender systems, topic models, and control. In this survey, we also discuss\nthe relationship and differences between Bayesian deep learning and other\nrelated topics like Bayesian treatment of neural networks.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Towards Bayesian Deep Learning: A Survey",
        "year": 2016
    },
    {
        "author": "[{'name': 'Tejas D. Kulkarni'}, {'name': 'Karthik R. Narasimhan'}, {'name': 'Ardavan Saeedi'}, {'name': 'Joshua B. Tenenbaum'}]",
        "day": 20,
        "id": "1604.06057v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.06057v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.06057v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Learning goal-directed behavior in environments with sparse feedback is a\nmajor challenge for reinforcement learning algorithms. The primary difficulty\narises due to insufficient exploration, resulting in an agent being unable to\nlearn robust value functions. Intrinsically motivated agents can explore new\nbehavior for its own sake rather than to directly solve problems. Such\nintrinsic behaviors could eventually help the agent solve tasks posed by the\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\nhierarchical value functions, operating at different temporal scales, with\nintrinsically motivated deep reinforcement learning. A top-level value function\nlearns a policy over intrinsic goals, and a lower-level function learns a\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\nflexible goal specifications, such as functions over entities and relations.\nThis provides an efficient space for exploration in complicated environments.\nWe demonstrate the strength of our approach on two problems with very sparse,\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\nthe classic ATARI game `Montezuma's Revenge'.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal\n  Abstraction and Intrinsic Motivation",
        "year": 2016
    },
    {
        "author": "[{'name': 'Deepak Pathak'}, {'name': 'Ross Girshick'}, {'name': 'Piotr Doll\u00e1r'}, {'name': 'Trevor Darrell'}, {'name': 'Bharath Hariharan'}]",
        "day": 19,
        "id": "1612.06370v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.06370v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.06370v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "This paper presents a novel yet intuitive approach to unsupervised feature\nlearning. Inspired by the human visual system, we explore whether low-level\nmotion-based grouping cues can be used to learn an effective visual\nrepresentation. Specifically, we use unsupervised motion-based segmentation on\nvideos to obtain segments, which we use as 'pseudo ground truth' to train a\nconvolutional network to segment objects from a single frame. Given the\nextensive evidence that motion plays a key role in the development of the human\nvisual system, we hope that this straightforward approach to unsupervised\nlearning will be more effective than cleverly designed 'pretext' tasks studied\nin the literature. Indeed, our extensive experiments show that this is the\ncase. When used for transfer learning on object detection, our representation\nsignificantly outperforms previous unsupervised approaches across multiple\nsettings, especially when training data for the target task is scarce.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Learning Features by Watching Objects Move",
        "year": 2016
    },
    {
        "author": "[{'name': 'Muhammad Ghifary'}, {'name': 'W. Bastiaan Kleijn'}, {'name': 'Mengjie Zhang'}]",
        "day": 21,
        "id": "1409.6041v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.6041v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.6041v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "We propose a simple neural network model to deal with the domain adaptation\nproblem in object recognition. Our model incorporates the Maximum Mean\nDiscrepancy (MMD) measure as a regularization in the supervised learning to\nreduce the distribution mismatch between the source and target domains in the\nlatent space. From experiments, we demonstrate that the MMD regularization is\nan effective tool to provide good domain adaptation models on both SURF\nfeatures and raw image pixels of a particular image data set. We also show that\nour proposed model, preceded by the denoising auto-encoder pretraining,\nachieves better performance than recent benchmark models on the same data sets.\nThis work represents the first study of MMD measure in the context of neural\nnetworks.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Domain Adaptive Neural Networks for Object Recognition",
        "year": 2014
    },
    {
        "author": "[{'name': 'Lionel Pigou'}, {'name': 'A\u00e4ron van den Oord'}, {'name': 'Sander Dieleman'}, {'name': 'Mieke Van Herreweghe'}, {'name': 'Joni Dambre'}]",
        "day": 5,
        "id": "1506.01911v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.01911v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.01911v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "Recent studies have demonstrated the power of recurrent neural networks for\nmachine translation, image captioning and speech recognition. For the task of\ncapturing temporal structure in video, however, there still remain numerous\nopen research questions. Current research suggests using a simple temporal\nfeature pooling strategy to take into account the temporal aspect of video. We\ndemonstrate that this method is not sufficient for gesture recognition, where\ntemporal information is more discriminative compared to general video\nclassification tasks. We explore deep architectures for gesture recognition in\nvideo and propose a new end-to-end trainable neural network architecture\nincorporating temporal convolutions and bidirectional recurrence. Our main\ncontributions are twofold; first, we show that recurrence is crucial for this\ntask; second, we show that adding temporal convolutions leads to significant\nimprovements. We evaluate the different approaches on the Montalbano gesture\nrecognition dataset, where we achieve state-of-the-art results.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Beyond Temporal Pooling: Recurrence and Temporal Convolutions for\n  Gesture Recognition in Video",
        "year": 2015
    },
    {
        "author": "[{'name': 'Rakesh Achanta'}, {'name': 'Trevor Hastie'}]",
        "day": 20,
        "id": "1509.05962v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.05962v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.05962v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "In this paper, we address the task of Optical Character Recognition(OCR) for\nthe Telugu script. We present an end-to-end framework that segments the text\nimage, classifies the characters and extracts lines using a language model. The\nsegmentation is based on mathematical morphology. The classification module,\nwhich is the most challenging task of the three, is a deep convolutional neural\nnetwork. The language is modelled as a third degree markov chain at the glyph\nlevel. Telugu script is a complex alphasyllabary and the language is\nagglutinative, making the problem hard. In this paper we apply the latest\nadvances in neural networks to achieve state-of-the-art error rates. We also\nreview convolutional neural networks in great detail and expound the\nstatistical justification behind the many tricks needed to make Deep Learning\nwork.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Telugu OCR Framework using Deep Learning",
        "year": 2015
    },
    {
        "author": "[{'name': 'Jeff Donahue'}, {'name': 'Philipp Kr\u00e4henb\u00fchl'}, {'name': 'Trevor Darrell'}]",
        "day": 31,
        "id": "1605.09782v7",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.09782v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.09782v7', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Adversarial Feature Learning",
        "year": 2016
    },
    {
        "author": "[{'name': 'Zachary C. Lipton'}]",
        "day": 10,
        "id": "1606.03490v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.03490v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.03490v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "The Mythos of Model Interpretability",
        "year": 2016
    },
    {
        "author": "[{'name': 'Sahil Garg'}, {'name': 'Irina Rish'}, {'name': 'Guillermo Cecchi'}, {'name': 'Aurelie Lozano'}]",
        "day": 22,
        "id": "1701.06106v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.06106v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.06106v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 1,
        "summary": "In this paper, we focus on online representation learning in non-stationary\nenvironments which may require continuous adaptation of model architecture. We\npropose a novel online dictionary-learning (sparse-coding) framework which\nincorporates the addition and deletion of hidden units (dictionary elements),\nand is inspired by the adult neurogenesis phenomenon in the dentate gyrus of\nthe hippocampus, known to be associated with improved cognitive function and\nadaptation to new environments. In the online learning setting, where new input\ninstances arrive sequentially in batches, the neuronal-birth is implemented by\nadding new units with random initial weights (random dictionary elements); the\nnumber of new units is determined by the current performance (representation\nerror) of the dictionary, higher error causing an increase in the birth rate.\nNeuronal-death is implemented by imposing l1/l2-regularization (group sparsity)\non the dictionary within the block-coordinate descent optimization at each\niteration of our online alternating minimization scheme, which iterates between\nthe code and dictionary updates. Finally, hidden unit connectivity adaptation\nis facilitated by introducing sparsity in dictionary elements. Our empirical\nevaluation on several real-life datasets (images and language) as well as on\nsynthetic data demonstrates that the proposed approach can considerably\noutperform the state-of-art fixed-size (nonadaptive) online sparse coding of\nMairal et al. (2009) in the presence of nonstationary data. Moreover, we\nidentify certain properties of the data (e.g., sparse inputs with nearly\nnon-overlapping supports) and of the model (e.g., dictionary sparsity)\nassociated with such improvements.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a\n  Changing World",
        "year": 2017
    },
    {
        "author": "[{'name': 'Weifeng Ge'}, {'name': 'Yizhou Yu'}]",
        "day": 28,
        "id": "1702.08690v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.08690v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.08690v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "Deep neural networks require a large amount of labeled training data during\nsupervised learning. However, collecting and labeling so much data might be\ninfeasible in many cases. In this paper, we introduce a source-target selective\njoint fine-tuning scheme for improving the performance of deep learning tasks\nwith insufficient training data. In this scheme, a target learning task with\ninsufficient training data is carried out simultaneously with another source\nlearning task with abundant training data. However, the source learning task\ndoes not use all existing training data. Our core idea is to identify and use a\nsubset of training images from the original source learning task whose\nlow-level characteristics are similar to those from the target learning task,\nand jointly fine-tune shared convolutional layers for both tasks. Specifically,\nwe compute descriptors from linear or nonlinear filter bank responses on\ntraining images from both tasks, and use such descriptors to search for a\ndesired subset of training samples for the source learning task.\n  Experiments demonstrate that our selective joint fine-tuning scheme achieves\nstate-of-the-art performance on multiple visual classification tasks with\ninsufficient training data for deep learning. Such tasks include Caltech 256,\nMIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to\nfine-tuning without a source domain, the proposed method can improve the\nclassification accuracy by 2% - 10% using a single model.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Borrowing Treasures from the Wealthy: Deep Transfer Learning through\n  Selective Joint Fine-tuning",
        "year": 2017
    },
    {
        "author": "[{'name': 'Tanmay Gupta'}, {'name': 'Kevin Shih'}, {'name': 'Saurabh Singh'}, {'name': 'Derek Hoiem'}]",
        "day": 2,
        "id": "1704.00260v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.00260v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.00260v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "An important goal of computer vision is to build systems that learn visual\nrepresentations over time that can be applied to many tasks. In this paper, we\ninvestigate a vision-language embedding as a core representation and show that\nit leads to better cross-task transfer than standard multi-task learning. In\nparticular, the task of visual recognition is aligned to the task of visual\nquestion answering by forcing each to use the same word-region embeddings. We\nshow this leads to greater inductive transfer from recognition to VQA than\nstandard multitask learning. Visual recognition also improves, especially for\ncategories that have relatively few recognition training labels but appear\noften in the VQA setting. Thus, our paper takes a small step towards creating\nmore general vision systems by showing the benefit of interpretable, flexible,\nand trainable core representations.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Aligned Image-Word Representations Improve Inductive Transfer Across\n  Vision-Language Tasks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Jan Hendrik Metzen'}, {'name': 'Mummadi Chaithanya Kumar'}, {'name': 'Thomas Brox'}, {'name': 'Volker Fischer'}]",
        "day": 19,
        "id": "1704.05712v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.05712v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.05712v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "While deep learning is remarkably successful on perceptual tasks, it was also\nshown to be vulnerable to adversarial perturbations of the input. These\nperturbations denote noise added to the input that was generated specifically\nto fool the system while being quasi-imperceptible for humans. More severely,\nthere even exist universal perturbations that are input-agnostic but fool the\nnetwork on the majority of inputs. While recent work has focused on image\nclassification, this work proposes attacks against semantic image segmentation:\nwe present an approach for generating (universal) adversarial perturbations\nthat make the network yield a desired target segmentation as output. We show\nempirically that there exist barely perceptible universal noise patterns which\nresult in nearly the same predicted segmentation for arbitrary inputs.\nFurthermore, we also show the existence of universal noise which removes a\ntarget class (e.g., all pedestrians) from the segmentation while leaving the\nsegmentation mostly unchanged otherwise.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Universal Adversarial Perturbations Against Semantic Image Segmentation",
        "year": 2017
    },
    {
        "author": "[{'name': 'Quynh Nguyen'}, {'name': 'Matthias Hein'}]",
        "day": 26,
        "id": "1704.08045v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08045v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08045v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "While the optimization problem behind deep neural networks is highly\nnon-convex, it is frequently observed in practice that training deep networks\nseems possible without getting stuck in suboptimal points. It has been argued\nthat this is the case as all local minima are close to being globally optimal.\nWe show that this is (almost) true, in fact almost all local minima are\nglobally optimal, for a fully connected network with squared loss and analytic\nactivation function given that the number of hidden units of one layer of the\nnetwork is larger than the number of training points and the network structure\nfrom this layer on is pyramidal.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "The loss surface of deep and wide neural networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Chris Donahue'}, {'name': 'Zachary C. Lipton'}, {'name': 'Akshay Balsubramani'}, {'name': 'Julian McAuley'}]",
        "day": 22,
        "id": "1705.07904v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.07904v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.07904v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "We propose a new algorithm for training generative adversarial networks that\njointly learns latent codes for both identities (e.g. individual humans) and\nobservations (e.g. specific photographs). By fixing the identity portion of the\nlatent codes, we can generate diverse images of the same subject, and by fixing\nthe observation portion, we can traverse the manifold of subjects while\nmaintaining contingent aspects such as lighting and pose. Our algorithm\nfeatures a pairwise training scheme in which each sample from the generator\nconsists of two images with a common identity code. Corresponding samples from\nthe real dataset consist of two distinct photographs of the same subject. In\norder to fool the discriminator, the generator must produce pairs that are\nphotorealistic, distinct, and appear to depict the same individual. We augment\nboth the DCGAN and BEGAN approaches with Siamese discriminators to facilitate\npairwise training. Experiments with human judges and an off-the-shelf face\nverification system demonstrate our algorithm's ability to generate convincing,\nidentity-matched photographs.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Semantically Decomposing the Latent Spaces of Generative Adversarial\n  Networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Mahesh Chandra Mukkamala'}, {'name': 'Matthias Hein'}]",
        "day": 17,
        "id": "1706.05507v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.05507v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.05507v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds",
        "year": 2017
    },
    {
        "author": "[{'name': 'Chunyuan Li'}, {'name': 'Hao Liu'}, {'name': 'Changyou Chen'}, {'name': 'Yunchen Pu'}, {'name': 'Liqun Chen'}, {'name': 'Ricardo Henao'}, {'name': 'Lawrence Carin'}]",
        "day": 5,
        "id": "1709.01215v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.01215v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.01215v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching",
        "year": 2017
    },
    {
        "author": "[{'name': 'Mateusz Buda'}, {'name': 'Atsuto Maki'}, {'name': 'Maciej A. Mazurowski'}]",
        "day": 15,
        "id": "1710.05381v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.05381v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.05381v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 10,
        "summary": "In this study, we systematically investigate the impact of class imbalance on\nclassification performance of convolutional neural networks (CNNs) and compare\nfrequently used methods to address the issue. Class imbalance is a common\nproblem that has been comprehensively studied in classical machine learning,\nyet very limited systematic research is available in the context of deep\nlearning. In our study, we use three benchmark datasets of increasing\ncomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of\nimbalance on classification and perform an extensive comparison of several\nmethods to address the issue: oversampling, undersampling, two-phase training,\nand thresholding that compensates for prior class probabilities. Our main\nevaluation metric is area under the receiver operating characteristic curve\n(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is\nassociated with notable difficulties in the context of imbalanced data. Based\non results from our experiments we conclude that (i) the effect of class\nimbalance on classification performance is detrimental; (ii) the method of\naddressing class imbalance that emerged as dominant in almost all analyzed\nscenarios was oversampling; (iii) oversampling should be applied to the level\nthat totally eliminates the imbalance, whereas undersampling can perform better\nwhen the imbalance is only removed to some extent; (iv) as opposed to some\nclassical machine learning models, oversampling does not necessarily cause\noverfitting of CNNs; (v) thresholding should be applied to compensate for prior\nclass probabilities when overall number of properly classified cases is of\ninterest.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A systematic study of the class imbalance problem in convolutional\n  neural networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Jan Kuka\u010dka'}, {'name': 'Vladimir Golkov'}, {'name': 'Daniel Cremers'}]",
        "day": 29,
        "id": "1710.10686v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.10686v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.10686v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 10,
        "summary": "Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62M45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Regularization for Deep Learning: A Taxonomy",
        "year": 2017
    },
    {
        "author": "[{'name': 'Elie Aljalbout'}, {'name': 'Vladimir Golkov'}, {'name': 'Yawar Siddiqui'}, {'name': 'Daniel Cremers'}]",
        "day": 23,
        "id": "1801.07648v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.07648v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.07648v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 1,
        "summary": "Clustering is a fundamental machine learning method. The quality of its\nresults is dependent on the data distribution. For this reason, deep neural\nnetworks can be used for learning better representations of the data. In this\npaper, we propose a systematic taxonomy for clustering with deep learning, in\naddition to a review of methods from the field. Based on our taxonomy, creating\nnew methods is more straightforward. We also propose a new approach which is\nbuilt on the taxonomy and surpasses some of the limitations of some previous\nwork. Our experimental evaluation on image datasets shows that the method\napproaches state-of-the-art clustering quality, and performs better in some\ncases.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62H30, 62M45, 91C20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3; I.2.6; I.5; I.5.3; I.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Clustering with Deep Learning: Taxonomy and New Methods",
        "year": 2018
    },
    {
        "author": "[{'name': 'Armand Zampieri'}, {'name': 'Guillaume Charpiat'}, {'name': 'Yuliya Tarabalka'}]",
        "day": 27,
        "id": "1802.09816v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.09816v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.09816v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing",
        "year": 2018
    },
    {
        "author": "[{'name': 'Li Yao'}, {'name': 'Atousa Torabi'}, {'name': 'Kyunghyun Cho'}, {'name': 'Nicolas Ballas'}, {'name': 'Christopher Pal'}, {'name': 'Hugo Larochelle'}, {'name': 'Aaron Courville'}]",
        "day": 27,
        "id": "1502.08029v5",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1502.08029v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1502.08029v5', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "Recent progress in using recurrent neural networks (RNNs) for image\ndescription has motivated the exploration of their application for video\ndescription. However, while images are static, working with videos requires\nmodeling their dynamic temporal structure and then properly integrating that\ninformation into a natural language description. In this context, we propose an\napproach that successfully takes into account both the local and global\ntemporal structure of videos to produce descriptions. First, our approach\nincorporates a spatial temporal 3-D convolutional neural network (3-D CNN)\nrepresentation of the short temporal dynamics. The 3-D CNN representation is\ntrained on video action recognition tasks, so as to produce a representation\nthat is tuned to human motion and behavior. Second we propose a temporal\nattention mechanism that allows to go beyond local temporal modeling and learns\nto automatically select the most relevant temporal segments given the\ntext-generating RNN. Our approach exceeds the current state-of-art for both\nBLEU and METEOR metrics on the Youtube2Text dataset. We also present results on\na new, larger and more challenging dataset of paired video and natural language\ndescriptions.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Describing Videos by Exploiting Temporal Structure",
        "year": 2015
    },
    {
        "author": "[{'name': 'Hao Wang'}, {'name': 'Xingjian Shi'}, {'name': 'Dit-Yan Yeung'}]",
        "day": 2,
        "id": "1611.00454v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.00454v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.00454v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 11,
        "summary": "Hybrid methods that utilize both content and rating information are commonly\nused in many recommender systems. However, most of them use either handcrafted\nfeatures or the bag-of-words representation as a surrogate for the content\ninformation but they are neither effective nor natural enough. To address this\nproblem, we develop a collaborative recurrent autoencoder (CRAE) which is a\ndenoising recurrent autoencoder (DRAE) that models the generation of content\nsequences in the collaborative filtering (CF) setting. The model generalizes\nrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n(CF-based) input and provides a new denoising scheme along with a novel\nlearnable pooling scheme for the recurrent autoencoder. To do this, we first\ndevelop a hierarchical Bayesian model for the DRAE and then generalize it to\nthe CF setting. The synergy between denoising and CF enables CRAE to make\naccurate recommendations while learning to fill in the blanks in sequences.\nExperiments on real-world datasets from different domains (CiteULike and\nNetflix) show that, by jointly modeling the order-aware generation of sequences\nfor the content information and performing CF for the ratings, CRAE is able to\nsignificantly outperform the state of the art on both the recommendation task\nbased on ratings and the sequence generation task based on content information.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n  the Blanks",
        "year": 2016
    },
    {
        "author": "[{'name': 'Laura Graesser'}, {'name': 'Abhinav Gupta'}, {'name': 'Lakshay Sharma'}, {'name': 'Evelina Bakhturina'}]",
        "day": 3,
        "id": "1712.00725v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.00725v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.00725v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Sentiment Classification using Images and Label Embeddings",
        "year": 2017
    },
    {
        "author": "[{'name': 'Hao Wang'}, {'name': 'Xingjian Shi'}, {'name': 'Dit-Yan Yeung'}]",
        "day": 2,
        "id": "1611.00448v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.00448v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.00448v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 11,
        "summary": "Neural networks (NN) have achieved state-of-the-art performance in various\napplications. Unfortunately in applications where training data is\ninsufficient, they are often prone to overfitting. One effective way to\nalleviate this problem is to exploit the Bayesian approach by using Bayesian\nneural networks (BNN). Another shortcoming of NN is the lack of flexibility to\ncustomize different distributions for the weights and neurons according to the\ndata, as is often done in probabilistic graphical models. To address these\nproblems, we propose a class of probabilistic neural networks, dubbed\nnatural-parameter networks (NPN), as a novel and lightweight Bayesian treatment\nof NN. NPN allows the usage of arbitrary exponential-family distributions to\nmodel the weights and neurons. Different from traditional NN and BNN, NPN takes\ndistributions as input and goes through layers of transformation before\nproducing distributions to match the target output distributions. As a Bayesian\ntreatment, efficient backpropagation (BP) is performed to learn the natural\nparameters for the distributions over both the weights and neurons. The output\ndistributions of each layer, as byproducts, may be used as second-order\nrepresentations for the associated tasks such as link prediction. Experiments\non real-world datasets show that NPN can achieve state-of-the-art performance.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks",
        "year": 2016
    },
    {
        "author": "[{'name': 'Misha Denil'}, {'name': 'Pulkit Agrawal'}, {'name': 'Tejas D Kulkarni'}, {'name': 'Tom Erez'}, {'name': 'Peter Battaglia'}, {'name': 'Nando de Freitas'}]",
        "day": 6,
        "id": "1611.01843v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.01843v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.01843v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 11,
        "summary": "When encountering novel objects, humans are able to infer a wide range of\nphysical properties such as mass, friction and deformability by interacting\nwith them in a goal driven way. This process of active interaction is in the\nsame spirit as a scientist performing experiments to discover hidden facts.\nRecent advances in artificial intelligence have yielded machines that can\nachieve superhuman performance in Go, Atari, natural language processing, and\ncomplex control problems; however, it is not clear that these systems can rival\nthe scientific intuition of even a young child. In this work we introduce a\nbasic set of tasks that require agents to estimate properties such as mass and\ncohesion of objects in an interactive simulated environment where they can\nmanipulate the objects and observe the consequences. We found that state of art\ndeep reinforcement learning methods can learn to perform the experiments\nnecessary to discover such hidden properties. By systematically manipulating\nthe problem difficulty and the cost incurred by the agent for performing\nexperiments, we found that agents learn different strategies that balance the\ncost of gathering information against the cost of making mistakes in different\nsituations.",
        "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning",
        "year": 2016
    },
    {
        "author": "[{'name': 'Tsung-Hsien Wen'}, {'name': 'David Vandyke'}, {'name': 'Nikola Mrksic'}, {'name': 'Milica Gasic'}, {'name': 'Lina M. Rojas-Barahona'}, {'name': 'Pei-Hao Su'}, {'name': 'Stefan Ultes'}, {'name': 'Steve Young'}]",
        "day": 15,
        "id": "1604.04562v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.04562v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.04562v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Teaching machines to accomplish tasks by conversing naturally with humans is\nchallenging. Currently, developing task-oriented dialogue systems requires\ncreating multiple components and typically this involves either a large amount\nof handcrafting, or acquiring costly labelled datasets to solve a statistical\nlearning problem for each component. In this work we introduce a neural\nnetwork-based text-in, text-out end-to-end trainable goal-oriented dialogue\nsystem along with a new way of collecting dialogue data based on a novel\npipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue\nsystems easily and without making too many assumptions about the task at hand.\nThe results show that the model can converse with human subjects naturally\nwhilst helping them to accomplish tasks in a restaurant search domain.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System",
        "year": 2016
    },
    {
        "author": "[{'name': 'Johannes Welbl'}, {'name': 'Guillaume Bouchard'}, {'name': 'Sebastian Riedel'}]",
        "day": 20,
        "id": "1604.05878v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.05878v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.05878v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Embedding-based Knowledge Base Completion models have so far mostly combined\ndistributed representations of individual entities or relations to compute\ntruth scores of missing links. Facts can however also be represented using\npairwise embeddings, i.e. embeddings for pairs of entities and relations. In\nthis paper we explore such bigram embeddings with a flexible Factorization\nMachine model and several ablations from it. We investigate the relevance of\nvarious bigram types on the fb15k237 dataset and find relative improvements\ncompared to a compositional model.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Factorization Machine Framework for Testing Bigram Embeddings in\n  Knowledgebase Completion",
        "year": 2016
    },
    {
        "author": "[{'name': 'Franck Dernoncourt'}, {'name': 'Ji Young Lee'}, {'name': 'Peter Szolovits'}]",
        "day": 15,
        "id": "1612.05251v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.05251v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.05251v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "Existing models based on artificial neural networks (ANNs) for sentence\nclassification often do not incorporate the context in which sentences appear,\nand classify sentences individually. However, traditional sentence\nclassification approaches have been shown to greatly benefit from jointly\nclassifying subsequent sentences, such as with conditional random fields. In\nthis work, we present an ANN architecture that combines the effectiveness of\ntypical ANN models to classify sentences in isolation, with the strength of\nstructured prediction. Our model achieves state-of-the-art results on two\ndifferent datasets for sequential sentence classification in medical abstracts.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Neural Networks for Joint Sentence Classification in Medical Paper\n  Abstracts",
        "year": 2016
    },
    {
        "author": "[{'name': 'Franck Dernoncourt'}, {'name': 'Ji Young Lee'}, {'name': 'Ozlem Uzuner'}, {'name': 'Peter Szolovits'}]",
        "day": 10,
        "id": "1606.03475v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.03475v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.03475v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "De-identification of Patient Notes with Recurrent Neural Networks",
        "year": 2016
    },
    {
        "author": "[{'name': 'Tsendsuren Munkhdalai'}, {'name': 'Hong Yu'}]",
        "day": 20,
        "id": "1610.06454v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.06454v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.06454v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 10,
        "summary": "Hypothesis testing is an important cognitive process that supports human\nreasoning. In this paper, we introduce a computational hypothesis testing\napproach based on memory augmented neural networks. Our approach involves a\nhypothesis testing loop that reconsiders and progressively refines a previously\nformed hypothesis in order to generate new hypotheses to test. We apply the\nproposed approach to language comprehension task by using Neural Semantic\nEncoders (NSE). Our NSE models achieve the state-of-the-art results showing an\nabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\nsingle and ensemble systems on standard machine comprehension benchmarks such\nas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Reasoning with Memory Augmented Neural Networks for Language\n  Comprehension",
        "year": 2016
    },
    {
        "author": "[{'name': 'W. James Murdoch'}, {'name': 'Arthur Szlam'}]",
        "day": 8,
        "id": "1702.02540v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.02540v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.02540v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "Although deep learning models have proven effective at solving problems in\nnatural language processing, the mechanism by which they come to their\nconclusions is often unclear. As a result, these models are generally treated\nas black boxes, yielding no insight of the underlying learned patterns. In this\npaper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new\napproach for tracking the importance of a given input to the LSTM for a given\noutput. By identifying consistently important patterns of words, we are able to\ndistill state of the art LSTMs on sentiment analysis and question answering\ninto a set of representative phrases. This representation is then\nquantitatively validated by using the extracted phrases to construct a simple,\nrule-based classifier which approximates the output of the LSTM.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Automatic Rule Extraction from Long Short Term Memory Networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Sebastian Gehrmann'}, {'name': 'Franck Dernoncourt'}, {'name': 'Yeran Li'}, {'name': 'Eric T. Carlson'}, {'name': 'Joy T. Wu'}, {'name': 'Jonathan Welt'}, {'name': 'John Foote Jr.'}, {'name': 'Edward T. Moseley'}, {'name': 'David W. Grant'}, {'name': 'Patrick D. Tyler'}, {'name': 'Leo Anthony Celi'}]",
        "day": 25,
        "id": "1703.08705v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.08705v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.08705v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 3,
        "summary": "Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping",
        "year": 2017
    },
    {
        "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}, {'name': 'Peter Szolovits'}]",
        "day": 5,
        "id": "1704.01523v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.01523v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.01523v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Over 50 million scholarly articles have been published: they constitute a\nunique repository of knowledge. In particular, one may infer from them\nrelations between scientific concepts, such as synonyms and hyponyms.\nArtificial neural networks have been recently explored for relation extraction.\nIn this work, we continue this line of work and present a system based on a\nconvolutional neural network to extract relations. Our model ranked first in\nthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific\narticles (subtask C).",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional\n  Neural Networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}, {'name': 'Peter Szolovits'}]",
        "day": 17,
        "id": "1705.06273v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.06273v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.06273v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for named-entity recognition (NER). In order to achieve high\nperformances, ANNs need to be trained on a large labeled dataset. However,\nlabels might be difficult to obtain for the dataset on which the user wants to\nperform NER: label scarcity is particularly pronounced for patient note\nde-identification, which is an instance of NER. In this work, we analyze to\nwhat extent transfer learning may address this issue. In particular, we\ndemonstrate that transferring an ANN model trained on a large labeled dataset\nto another dataset with a limited number of labels improves upon the\nstate-of-the-art results on two different datasets for patient note\nde-identification.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Transfer Learning for Named-Entity Recognition with Neural Networks",
        "year": 2017
    },
    {
        "author": "[{'name': 'Sai Rajeswar'}, {'name': 'Sandeep Subramanian'}, {'name': 'Francis Dutil'}, {'name': 'Christopher Pal'}, {'name': 'Aaron Courville'}]",
        "day": 31,
        "id": "1705.10929v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10929v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10929v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "Generative Adversarial Networks (GANs) have gathered a lot of attention from\nthe computer vision community, yielding impressive results for image\ngeneration. Advances in the adversarial generation of natural language from\nnoise however are not commensurate with the progress made in generating images,\nand still lag far behind likelihood based methods. In this paper, we take a\nstep towards generating natural language with a GAN objective alone. We\nintroduce a simple baseline that addresses the discrete output space problem\nwithout relying on gradient estimators and show that it is able to achieve\nstate-of-the-art results on a Chinese poem generation dataset. We present\nquantitative results on generating sentences from context-free and\nprobabilistic context-free grammars, and qualitative language modeling results.\nA conditional version is also described that can generate sequences conditioned\non sentence characteristics.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Adversarial Generation of Natural Language",
        "year": 2017
    },
    {
        "author": "[{'name': 'Leila Arras'}, {'name': 'Gr\u00e9goire Montavon'}, {'name': 'Klaus-Robert M\u00fcller'}, {'name': 'Wojciech Samek'}]",
        "day": 22,
        "id": "1706.07206v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.07206v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.07206v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
        "year": 2017
    },
    {
        "author": "[{'name': 'Emmanuel Dufourq'}, {'name': 'Bruce A. Bassett'}]",
        "day": 20,
        "id": "1709.06990v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.06990v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.06990v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "Can textual data be compressed intelligently without losing accuracy in\nevaluating sentiment? In this study, we propose a novel evolutionary\ncompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),\nwhich makes use of Parts-of-Speech tags to compress text in a way that\nsacrifices minimal classification accuracy when used in conjunction with\nsentiment analysis algorithms. An analysis of PARSEC with eight commercial and\nnon-commercial sentiment analysis algorithms on twelve English sentiment data\nsets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss\nin sentiment classification accuracy for (20%, 50%, 75%) data compression with\nPARSEC using LingPipe, the most accurate of the sentiment algorithms. Other\nsentiment analysis algorithms are more severely affected by compression. We\nconclude that significant compression of text data is possible for sentiment\nanalysis depending on the accuracy demands of the specific application and the\nspecific sentiment analysis algorithm used.",
        "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms",
        "year": 2017
    },
    {
        "author": "[{'name': 'Kartik Audhkhasi'}, {'name': 'Brian Kingsbury'}, {'name': 'Bhuvana Ramabhadran'}, {'name': 'George Saon'}, {'name': 'Michael Picheny'}]",
        "day": 8,
        "id": "1712.03133v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.03133v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.03133v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition",
        "year": 2017
    },
    {
        "author": "[{'name': 'Huijuan Xu'}, {'name': 'Kate Saenko'}]",
        "day": 17,
        "id": "1511.05234v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.05234v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.05234v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 11,
        "summary": "We address the problem of Visual Question Answering (VQA), which requires\njoint image and language understanding to answer a question about a given\nphotograph. Recent approaches have applied deep image captioning methods based\non convolutional-recurrent networks to this problem, but have failed to model\nspatial inference. To remedy this, we propose a model we call the Spatial\nMemory Network and apply it to the VQA task. Memory networks are recurrent\nneural networks with an explicit attention mechanism that selects certain parts\nof the information stored in memory. Our Spatial Memory Network stores neuron\nactivations from different spatial regions of the image in its memory, and uses\nthe question to choose relevant regions for computing the answer, a process of\nwhich constitutes a single \"hop\" in the network. We propose a novel spatial\nattention architecture that aligns words with image patches in the first hop,\nand obtain improved results by adding a second attention hop which considers\nthe whole question to choose visual evidence based on the results of the first\nhop. To better understand the inference process learned by the network, we\ndesign synthetic questions that specifically require spatial inference and\nvisualize the attention weights. We evaluate our model on two published visual\nquestion answering datasets, DAQUAR [1] and VQA [2], and obtain improved\nresults compared to a strong deep baseline model (iBOWIMG) which concatenates\nimage and question features to predict the answer [3].",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for\n  Visual Question Answering",
        "year": 2015
    },
    {
        "author": "[{'name': 'Yuetan Lin'}, {'name': 'Zhangyang Pang'}, {'name': 'Donghui Wang'}, {'name': 'Yueting Zhuang'}]",
        "day": 22,
        "id": "1702.06700v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.06700v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.06700v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 2,
        "summary": "Visual question answering (VQA) has witnessed great progress since May, 2015\nas a classic problem unifying visual and textual data into a system. Many\nenlightening VQA works explore deep into the image and question encodings and\nfusing methods, of which attention is the most effective and infusive\nmechanism. Current attention based methods focus on adequate fusion of visual\nand textual features, but lack the attention to where people focus to ask\nquestions about the image. Traditional attention based methods attach a single\nvalue to the feature at each spatial location, which losses many useful\ninformation. To remedy these problems, we propose a general method to perform\nsaliency-like pre-selection on overlapped region features by the interrelation\nof bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication\nbased attention method to capture more competent correlation information\nbetween visual and textual features. We conduct experiments on the large-scale\nCOCO-VQA dataset and analyze the effectiveness of our model demonstrated by\nstrong empirical results.",
        "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Task-driven Visual Saliency and Attention-based Visual Question\n  Answering",
        "year": 2017
    },
    {
        "author": "[{'name': 'Akash Kumar Dhaka'}, {'name': 'Giampiero Salvi'}]",
        "day": 29,
        "id": "1606.09163v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.09163v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.09163v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "We present a systematic analysis on the performance of a phonetic recogniser\nwhen the window of input features is not symmetric with respect to the current\nframe. The recogniser is based on Context Dependent Deep Neural Networks\n(CD-DNNs) and Hidden Markov Models (HMMs). The objective is to reduce the\nlatency of the system by reducing the number of future feature frames required\nto estimate the current output. Our tests performed on the TIMIT database show\nthat the performance does not degrade when the input window is shifted up to 5\nframes in the past compared to common practice (no future frame). This\ncorresponds to improving the latency by 50 ms in our settings. Our tests also\nshow that the best results are not obtained with the symmetric window commonly\nemployed, but with an asymmetric window with eight past and two future context\nframes, although this observation should be confirmed on other data sets. The\nreduction in latency suggested by our results is critical for specific\napplications such as real-time lip synchronisation for tele-presence, but may\nalso be beneficial in general applications to improve the lag in human-machine\nspoken interaction.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Optimising The Input Window Alignment in CD-DNN Based Phoneme\n  Recognition for Low Latency Processing",
        "year": 2016
    },
    {
        "author": "[{'name': 'Peng Qian'}, {'name': 'Xipeng Qiu'}, {'name': 'Xuanjing Huang'}]",
        "day": 22,
        "id": "1604.06635v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.06635v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.06635v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Bridging LSTM Architecture and the Neural Dynamics during Reading",
        "year": 2016
    },
    {
        "author": "[{'name': 'Jiwei Li'}]",
        "day": 11,
        "id": "1412.3714v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.3714v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.3714v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "This paper addresses how a recursive neural network model can automatically\nleave out useless information and emphasize important evidence, in other words,\nto perform \"weight tuning\" for higher-level representation acquisition. We\npropose two models, Weighted Neural Network (WNN) and Binary-Expectation Neural\nNetwork (BENN), which automatically control how much one specific unit\ncontributes to the higher-level representation. The proposed model can be\nviewed as incorporating a more powerful compositional function for embedding\nacquisition in recursive neural networks. Experimental results demonstrate the\nsignificant improvement over standard neural models.",
        "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Feature Weight Tuning for Recursive Neural Networks",
        "year": 2014
    },
    {
        "author": "[{'name': 'Sadikin Mujiono'}, {'name': 'Mohamad Ivan Fanany'}, {'name': 'Chan Basaruddin'}]",
        "day": 6,
        "id": "1610.01891v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.01891v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.01891v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 10,
        "summary": "One essential task in information extraction from the medical corpus is drug\nname recognition. Compared with text sources come from other domains, the\nmedical text is special and has unique characteristics. In addition, the\nmedical text mining poses more challenges, e.g., more unstructured text, the\nfast growing of new terms addition, a wide range of name variation for the same\ndrug. The mining is even more challenging due to the lack of labeled dataset\nsources and external knowledge, as well as multiple token representations for a\nsingle drug name that is more common in the real application setting. Although\nmany approaches have been proposed to overwhelm the task, some problems\nremained with poor F-score performance (less than 0.75). This paper presents a\nnew treatment in data representation techniques to overcome some of those\nchallenges. We propose three data representation techniques based on the\ncharacteristics of word distribution and word similarities as a result of word\nembedding training. The first technique is evaluated with the standard NN\nmodel, i.e., MLP (Multi-Layer Perceptrons). The second technique involves two\ndeep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked\nDenoising Encoders). The third technique represents the sentence as a sequence\nthat is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term\nMemory). In extracting the drug name entities, the third technique gives the\nbest F-score performance compared to the state of the art, with its average\nF-score being 0.8645.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68Txx', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A New Data Representation Based on Training Data Characteristics to\n  Extract Drug Named-Entity in Medical Text",
        "year": 2016
    },
    {
        "author": "[{'name': 'Eric Malmi'}, {'name': 'Pyry Takala'}, {'name': 'Hannu Toivonen'}, {'name': 'Tapani Raiko'}, {'name': 'Aristides Gionis'}]",
        "day": 18,
        "id": "1505.04771v2",
        "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1145/2939672.2939679', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1505.04771v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1505.04771v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "Writing rap lyrics requires both creativity to construct a meaningful,\ninteresting story and lyrical skills to produce complex rhyme patterns, which\nform the cornerstone of good flow. We present a rap lyrics generation method\nthat captures both of these aspects. First, we develop a prediction model to\nidentify the next line of existing lyrics from a set of candidate next lines.\nThis model is based on two machine-learning techniques: the RankSVM algorithm\nand a deep neural network model with a novel structure. Results show that the\nprediction model can identify the true next line among 299 randomly selected\nlines with an accuracy of 17%, i.e., over 50 times more likely than by random.\nSecond, we employ the prediction model to combine lines from existing songs,\nproducing lyrics with rhyme and a meaning. An evaluation of the produced lyrics\nshows that in terms of quantitative rhyme density, the method outperforms the\nbest human rappers by 21%. The rap lyrics generator has been deployed as an\nonline tool called DeepBeat, and the performance of the tool has been assessed\nby analyzing its usage logs. This analysis shows that machine-learned rankings\ncorrelate with user preferences.",
        "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; H.3.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "DopeLearning: A Computational Approach to Rap Lyrics Generation",
        "year": 2015
    },
    {
        "author": "[{'name': 'Shengxian Wan'}, {'name': 'Yanyan Lan'}, {'name': 'Jun Xu'}, {'name': 'Jiafeng Guo'}, {'name': 'Liang Pang'}, {'name': 'Xueqi Cheng'}]",
        "day": 15,
        "id": "1604.04378v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.04378v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.04378v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 4,
        "summary": "Semantic matching, which aims to determine the matching degree between two\ntexts, is a fundamental problem for many NLP applications. Recently, deep\nlearning approach has been applied to this problem and significant improvements\nhave been achieved. In this paper, we propose to view the generation of the\nglobal interaction between two texts as a recursive process: i.e. the\ninteraction of two texts at each position is a composition of the interactions\nbetween their prefixes as well as the word level interaction at the current\nposition. Based on this idea, we propose a novel deep architecture, namely\nMatch-SRNN, to model the recursive matching structure. Firstly, a tensor is\nconstructed to capture the word level interactions. Then a spatial RNN is\napplied to integrate the local interactions recursively, with importance\ndetermined by four types of gates. Finally, the matching score is calculated\nbased on the global interaction. We show that, after degenerated to the exact\nmatching scenario, Match-SRNN can approximate the dynamic programming process\nof longest common subsequence. Thus, there exists a clear interpretation for\nMatch-SRNN. Our experiments on two semantic matching tasks showed the\neffectiveness of Match-SRNN, and its ability of visualizing the learned\nmatching structure.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN",
        "year": 2016
    },
    {
        "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Alexander G. Ororbia II'}, {'name': 'Joelle Pineau'}, {'name': 'Aaron Courville'}]",
        "day": 1,
        "id": "1612.00377v4",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.00377v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.00377v4', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 12,
        "summary": "Advances in neural variational inference have facilitated the learning of\npowerful directed graphical models with continuous latent variables, such as\nvariational autoencoders. The hope is that such models will learn to represent\nrich, multi-modal latent factors in real-world data, such as natural language\ntext. However, current models often assume simplistic priors on the latent\nvariables - such as the uni-modal Gaussian distribution - which are incapable\nof representing complex latent factors efficiently. To overcome this\nrestriction, we propose the simple, but highly flexible, piecewise constant\ndistribution. This distribution has the capacity to represent an exponential\nnumber of modes of a latent target distribution, while remaining mathematically\ntractable. Our results demonstrate that incorporating this new latent\ndistribution into different models yields substantial improvements in natural\nlanguage processing tasks such as document modeling and natural language\ngeneration for dialogue.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Piecewise Latent Variables for Neural Variational Text Processing",
        "year": 2016
    },
    {
        "author": "[{'name': 'Baolin Peng'}, {'name': 'Kaisheng Yao'}]",
        "day": 31,
        "id": "1506.00195v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.00195v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.00195v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 5,
        "summary": "Recurrent Neural Networks (RNNs) have become increasingly popular for the\ntask of language understanding. In this task, a semantic tagger is deployed to\nassociate a semantic label to each word in an input sequence. The success of\nRNN may be attributed to its ability to memorize long-term dependence that\nrelates the current-time semantic label prediction to the observations many\ntime instances away. However, the memory capacity of simple RNNs is limited\nbecause of the gradient vanishing and exploding problem. We propose to use an\nexternal memory to improve memorization capability of RNNs. We conducted\nexperiments on the ATIS dataset, and observed that the proposed model was able\nto achieve the state-of-the-art results. We compare our proposed model with\nalternative models and report analysis results that may provide insights for\nfuture research.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Recurrent Neural Networks with External Memory for Language\n  Understanding",
        "year": 2015
    },
    {
        "author": "[{'name': 'Alessandro Sordoni'}, {'name': 'Michel Galley'}, {'name': 'Michael Auli'}, {'name': 'Chris Brockett'}, {'name': 'Yangfeng Ji'}, {'name': 'Margaret Mitchell'}, {'name': 'Jian-Yun Nie'}, {'name': 'Jianfeng Gao'}, {'name': 'Bill Dolan'}]",
        "day": 22,
        "id": "1506.06714v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.06714v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.06714v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "We present a novel response generation system that can be trained end to end\non large quantities of unstructured Twitter conversations. A neural network\narchitecture is used to address sparsity issues that arise when integrating\ncontextual information into classic statistical models, allowing the system to\ntake into account previous dialog utterances. Our dynamic-context generative\nmodels show consistent gains over both context-sensitive and\nnon-context-sensitive Machine Translation and Information Retrieval baselines.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "A Neural Network Approach to Context-Sensitive Generation of\n  Conversational Responses",
        "year": 2015
    },
    {
        "author": "[{'name': 'Ryan Lowe'}, {'name': 'Nissan Pow'}, {'name': 'Iulian Serban'}, {'name': 'Joelle Pineau'}]",
        "day": 30,
        "id": "1506.08909v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.08909v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.08909v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 6,
        "summary": "This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost\n1 million multi-turn dialogues, with a total of over 7 million utterances and\n100 million words. This provides a unique resource for research into building\ndialogue managers based on neural language models that can make use of large\namounts of unlabeled data. The dataset has both the multi-turn property of\nconversations in the Dialog State Tracking Challenge datasets, and the\nunstructured nature of interactions from microblog services such as Twitter. We\nalso describe two neural learning architectures suitable for analyzing this\ndataset, and provide benchmark performance on the task of selecting the best\nnext response.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured\n  Multi-Turn Dialogue Systems",
        "year": 2015
    },
    {
        "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Alessandro Sordoni'}, {'name': 'Yoshua Bengio'}, {'name': 'Aaron Courville'}, {'name': 'Joelle Pineau'}]",
        "day": 17,
        "id": "1507.04808v3",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1507.04808v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1507.04808v3', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 7,
        "summary": "We investigate the task of building open domain, conversational dialogue\nsystems based on large dialogue corpora using generative models. Generative\nmodels produce system responses that are autonomously generated word-by-word,\nopening up the possibility for realistic, flexible interactions. In support of\nthis goal, we extend the recently proposed hierarchical recurrent\nencoder-decoder neural network to the dialogue domain, and demonstrate that\nthis model is competitive with state-of-the-art neural language models and\nback-off n-gram models. We investigate the limitations of this and similar\napproaches, and show how its performance can be improved by bootstrapping the\nlearning from a larger question-answer pair corpus and from pretrained word\nembeddings.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Building End-To-End Dialogue Systems Using Generative Hierarchical\n  Neural Network Models",
        "year": 2015
    },
    {
        "author": "[{'name': 'Dzmitry Bahdanau'}, {'name': 'Jan Chorowski'}, {'name': 'Dmitriy Serdyuk'}, {'name': 'Philemon Brakel'}, {'name': 'Yoshua Bengio'}]",
        "day": 18,
        "id": "1508.04395v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.04395v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.04395v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 8,
        "summary": "Many of the current state-of-the-art Large Vocabulary Continuous Speech\nRecognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov\nModels (HMMs). Most of these systems contain separate components that deal with\nthe acoustic modelling, language modelling and sequence decoding. We\ninvestigate a more direct approach in which the HMM is replaced with a\nRecurrent Neural Network (RNN) that performs sequence prediction directly at\nthe character level. Alignment between the input features and the desired\ncharacter sequence is learned automatically by an attention mechanism built\ninto the RNN. For each predicted character, the attention mechanism scans the\ninput sequence and chooses relevant frames. We propose two methods to speed up\nthis operation: limiting the scan to a subset of most promising frames and\npooling over time the information contained in neighboring frames, thereby\nreducing source sequence length. Integrating an n-gram language model into the\ndecoding process yields recognition accuracies similar to other HMM-free\nRNN-based approaches.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "End-to-End Attention-based Large Vocabulary Speech Recognition",
        "year": 2015
    },
    {
        "author": "[{'name': 'Baolin Peng'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}, {'name': 'Kam-Fai Wong'}]",
        "day": 22,
        "id": "1508.05508v1",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.05508v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.05508v1', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 8,
        "summary": "We propose Neural Reasoner, a framework for neural network-based reasoning\nover natural language sentences. Given a question, Neural Reasoner can infer\nover multiple supporting facts and find an answer to the question in specific\nforms. Neural Reasoner has 1) a specific interaction-pooling mechanism,\nallowing it to examine multiple facts, and 2) a deep architecture, allowing it\nto model the complicated logical relations in reasoning tasks. Assuming no\nparticular structure exists in the question and facts, Neural Reasoner is able\nto accommodate different types of reasoning and different forms of language\nexpressions. Despite the model complexity, Neural Reasoner can still be trained\neffectively in an end-to-end manner. Our empirical studies show that Neural\nReasoner can outperform existing neural reasoning systems with remarkable\nmargins on two difficult artificial tasks (Positional Reasoning and Path\nFinding) proposed in [8]. For example, it improves the accuracy on Path\nFinding(10K) from 33.4% [6] to over 98%.",
        "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Towards Neural Network-based Reasoning",
        "year": 2015
    },
    {
        "author": "[{'name': 'Hongyuan Mei'}, {'name': 'Mohit Bansal'}, {'name': 'Matthew R. Walter'}]",
        "day": 2,
        "id": "1509.00838v2",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.00838v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.00838v2', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "We propose an end-to-end, domain-independent neural encoder-aligner-decoder\nmodel for selective generation, i.e., the joint task of content selection and\nsurface realization. Our model first encodes a full set of over-determined\ndatabase event records via an LSTM-based recurrent neural network, then\nutilizes a novel coarse-to-fine aligner to identify the small subset of salient\nrecords to talk about, and finally employs a decoder to generate free-form\ndescriptions of the aligned, selected records. Our model achieves the best\nselection and generation results reported to-date (with 59% relative\nimprovement in generation) on the benchmark WeatherGov dataset, despite using\nno specialized features or linguistic resources. Using an improved k-nearest\nneighbor beam filter helps further. We also perform a series of ablations and\nvisualizations to elucidate the contributions of our key model components.\nLastly, we evaluate the generalizability of our model on the RoboCup dataset,\nand get results that are competitive with or better than the state-of-the-art,\ndespite being severely data-starved.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "What to talk about and how? Selective Generation using LSTMs with\n  Coarse-to-Fine Alignment",
        "year": 2015
    },
    {
        "author": "[{'name': 'Tim Rockt\u00e4schel'}, {'name': 'Edward Grefenstette'}, {'name': 'Karl Moritz Hermann'}, {'name': 'Tom\u00e1\u0161 Ko\u010disk\u00fd'}, {'name': 'Phil Blunsom'}]",
        "day": 22,
        "id": "1509.06664v4",
        "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.06664v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.06664v4', 'type': 'application/pdf', 'title': 'pdf'}]",
        "month": 9,
        "summary": "While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset.",
        "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
        "title": "Reasoning about Entailment with Neural Attention",
        "year": 2015
    }
]